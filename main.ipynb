{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepod.models.tabular import DevNet, PReNet, DeepSAD, FeaWAD, RoSAS\n",
    "from deepod.metrics import tabular_metrics\n",
    "from autoencodernn import *\n",
    "from tapnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for filename in tqdm(os.listdir('./data/')):\n",
    "    if 'preprocessed' in filename:\n",
    "        dfs.append(pd.read_csv(f'./data/{filename}', index_col = 0))\n",
    "df = pd.concat(dfs).reset_index(drop = True)\n",
    "del(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_df, test_df = train_test_split(df, test_size = 0.2, stratify = df['label'])\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size = 0.125, stratify = train_valid_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['label'], axis = 1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_valid = valid_df.drop(['label'], axis = 1)\n",
    "y_valid = valid_df['label']\n",
    "\n",
    "X_test = test_df.drop(['label'], axis = 1)\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('./checkpoint/train_df.csv', index_col = 0)\n",
    "# valid_df = pd.read_csv('./checkpoint/valid_df.csv', index_col = 0)\n",
    "# test_df = pd.read_csv('./checkpoint/test_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('./checkpoint/x_train.csv')\n",
    "# y_train = pd.read_csv('./checkpoint/y_train.csv')\n",
    "\n",
    "# X_valid = pd.read_csv('./checkpoint/x_valid.csv')\n",
    "# y_valid = pd.read_csv('./checkpoint/y_valid.csv')\n",
    "\n",
    "# X_test = pd.read_csv('./checkpoint/x_test.csv')\n",
    "# y_test = pd.read_csv('./checkpoint/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_preprocessing(df1, df2, df3):\n",
    "    df1['type'] = 'train'\n",
    "    df2['type'] = 'valid'\n",
    "    df3['type'] = 'test'\n",
    "\n",
    "    df = pd.concat([df1, df2, df3]).reset_index(drop = True)\n",
    "\n",
    "    country_onehot = pd.get_dummies(df['country']).astype(int)\n",
    "    risk_grades = df[['region_risk_grade', 'city_risk_grade', 'name_risk_grade']]\n",
    "    browser_onehot = pd.get_dummies(df['browser_name']).astype(int)\n",
    "    os_onehot = pd.get_dummies(df['os_name']).astype(int)\n",
    "    legacys = df[['browser_is_legacy', 'os_is_legacy']]\n",
    "    device_types = pd.get_dummies(df['device_type']).astype(int)\n",
    "    rtts = df['rtt']\n",
    "    type = df['type']\n",
    "    label = df['label']\n",
    "    df = pd.concat([country_onehot, risk_grades, browser_onehot, os_onehot, legacys, device_types, rtts, type, label], axis = 1)\n",
    "\n",
    "    df1 = df[df['type'] == 'train'].drop('type', axis = 1)\n",
    "    df2 = df[df['type'] == 'valid'].drop('type', axis = 1)\n",
    "    df3 = df[df['type'] == 'test'].drop('type', axis = 1)\n",
    "\n",
    "    return df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detection\n",
    "print('Anomaly Detection Model')\n",
    "ad_model_names = ['DevNet', 'PReNet', 'DeepSAD', 'FeaWAD', 'RoSAS']\n",
    "ad_models = [\n",
    "    # DevNet(),           # 86.5s\n",
    "    # PReNet(),           # Too long. (2.4 hours)\n",
    "    DeepSAD(epochs = 50),          # 75.4s\n",
    "    # FeaWAD(epochs = 10000, lr = 0.01),           # Very fast but poor.\n",
    "    # RoSAS(),            # Too long.\n",
    "]\n",
    "\n",
    "train_df_ad, valid_df_ad, test_df_ad = anomaly_preprocessing(train_df, valid_df, test_df)\n",
    "\n",
    "X_train_ad = train_df_ad.drop(['label'], axis = 1)\n",
    "y_train_ad = train_df_ad['label']\n",
    "\n",
    "X_valid_ad = valid_df_ad.drop(['label'], axis = 1)\n",
    "y_valid_ad = valid_df_ad['label']\n",
    "\n",
    "X_test_ad = test_df_ad.drop(['label'], axis = 1)\n",
    "y_test_ad = test_df_ad['label']\n",
    "\n",
    "for model_name, model in zip(ad_model_names, ad_models):\n",
    "    print('start -', datetime.now())\n",
    "    \n",
    "    model.fit(X_train_ad.to_numpy(), y_train_ad.to_numpy())\n",
    "    print('Train Finish')\n",
    "    pred_train = (model.decision_function(X_train_ad.to_numpy()) > 0.5).astype(int)\n",
    "    auc_train, ap_train, f1_train = tabular_metrics(y_train_ad, pred_train)\n",
    "    \n",
    "    pred_valid = (model.decision_function(X_valid_ad.to_numpy()) > 0.5).astype(int)\n",
    "    auc_valid, ap_valid, f1_valid = tabular_metrics(y_valid_ad, pred_valid)\n",
    "    \n",
    "    print(f'Trained with {model}')\n",
    "    print(f'Train - AUC: {auc_train}, AP: {ap_train}, F1: {f1_train}')\n",
    "    print(f'Valid - AUC: {auc_valid}, AP: {ap_valid}, F1: {f1_valid}')\n",
    "\n",
    "    models.append(model)\n",
    "    print('end -', datetime.now(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: For faster execution, use this cell and comment the upper one.\n",
    "# with open('./checkpoint/deepsad.pkl', 'rb') as f:\n",
    "#     deepsad_model = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoder + NN\n",
    "print('AutoEncoder + NN Model')\n",
    "autoencoder_nn_model = model_v2(\n",
    "    train_data = train_df,          # Train set\n",
    "    valid_data = valid_df,          # Validation set\n",
    "    test_data = test_df,            # Test set\n",
    "    criteria = 0.5,                 # Classification threshold\n",
    "    split_ratio = [7, 1, 2],        # split ratio (format: [train,validation,test])\n",
    "    autoencoder_epochs = 50,        # epochs of autoencoder\n",
    "    classifier_epochs = 200,        # epochs of classifier\n",
    "    weight_for_attack = 15,         # weight for attack\n",
    ")\n",
    "\n",
    "models.append(autoencoder_nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: For faster execution, use this cell and comment the upper one.\n",
    "# with open('./checkpoint/autoencoder_nn.pkl', 'rb') as f:\n",
    "#     autoencoder_nn_model = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabNet\n",
    "print('TabNet Model')\n",
    "selected_columns = ['country_code', 'region', 'city_risk_grade', 'name_risk_grade', 'login_success', 'browser_is_legacy', 'os_is_legacy', 'rtt', 'device_type', 'label']\n",
    "categorical_columns = ['country_code', 'device_type', 'region']\n",
    "\n",
    "tabnet_model = TabNetModel(train_df, valid_df, test_df, selected_columns, categorical_columns, 'label')         #, pre_train_epochs = 5, epochs = 5)\n",
    "models.append(tabnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: For faster execution, use this cell and comment the upper one.\n",
    "# with open('./checkpoint/tabnet.pkl', 'rb') as f:\n",
    "#     tabnet_model = pickle.load(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_pred = (deepsad_model.decision_function(X_test_ad.to_numpy()) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.to_numpy(), anomaly_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test.to_numpy(), anomaly_pred))\n",
    "print(precision_score(y_test.to_numpy(), anomaly_pred))\n",
    "print(recall_score(y_test.to_numpy(), anomaly_pred))\n",
    "print(f1_score(y_test.to_numpy(), anomaly_pred))\n",
    "print(geometric_mean_score(y_test.to_numpy(), anomaly_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_df = autoencoder_nn_model.predicted_df\n",
    "autonn_pred = an_df['Predicted Label'].to_numpy().astype(int)\n",
    "print(classification_report(an_df['Actual Label'], an_df['Predicted Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(an_df['Actual Label'].to_numpy(), autonn_pred))\n",
    "print(precision_score(an_df['Actual Label'].to_numpy(), autonn_pred))\n",
    "print(recall_score(an_df['Actual Label'].to_numpy(), autonn_pred))\n",
    "print(f1_score(an_df['Actual Label'].to_numpy(), autonn_pred))\n",
    "print(geometric_mean_score(an_df['Actual Label'].to_numpy(), autonn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_soft = tabnet_model.clf.predict_proba(tabnet_model.X_test.values)[:, 1]\n",
    "tabnet_pred = tabnet_soft > 0.5\n",
    "print(classification_report(tabnet_model.y_test, tabnet_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(tabnet_model.y_test, tabnet_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test.to_numpy(), tabnet_pred))\n",
    "print(precision_score(y_test.to_numpy(), tabnet_pred))\n",
    "print(recall_score(y_test.to_numpy(), tabnet_pred))\n",
    "print(f1_score(y_test.to_numpy(), tabnet_pred))\n",
    "print(geometric_mean_score(y_test.to_numpy(), tabnet_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp1 = ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), anomaly_pred, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})\n",
    "disp2 = ConfusionMatrixDisplay.from_predictions(an_df['Actual Label'].astype(int), an_df['Predicted Label'].astype(int), normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})\n",
    "disp3 = ConfusionMatrixDisplay.from_predictions(tabnet_model.y_test, tabnet_pred, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority Voting\n",
    "majority_pred = (np.stack([anomaly_pred, autonn_pred, tabnet_pred]).mean(axis = 0) > 0.5).astype(int)\n",
    "majority_disp = ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), majority_pred, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test.to_numpy(), majority_pred))\n",
    "print(precision_score(y_test.to_numpy(), majority_pred))\n",
    "print(recall_score(y_test.to_numpy(), majority_pred))\n",
    "print(f1_score(y_test.to_numpy(), majority_pred))\n",
    "print(geometric_mean_score(y_test.to_numpy(), majority_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or Voting\n",
    "or_pred = (np.stack([anomaly_pred, autonn_pred, tabnet_pred]).sum(axis = 0) != 0).astype(int)\n",
    "or_disp = ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test.to_numpy(), or_pred))\n",
    "print(precision_score(y_test.to_numpy(), or_pred))\n",
    "print(recall_score(y_test.to_numpy(), or_pred))\n",
    "print(f1_score(y_test.to_numpy(), or_pred))\n",
    "print(geometric_mean_score(y_test.to_numpy(), or_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Voting\n",
    "deepsad_soft = deepsad_model.decision_function(X_test_ad.to_numpy())\n",
    "autonn_soft = an_df['Probability'].to_numpy()\n",
    "# tabnet_soft = tabnet_model.clf.predict_proba(tabnet_model.X_test.values)[:, 1]\n",
    "tabnet_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./checkpoint/deepsad_soft.pkl', 'wb') as f:\n",
    "    pickle.dump(deepsad_soft, f)\n",
    "with open('./checkpoint/autonn_soft.pkl', 'wb') as f:\n",
    "    pickle.dump(autonn_soft, f)\n",
    "with open('./checkpoint/tabnet_soft.pkl', 'wb') as f:\n",
    "    pickle.dump(tabnet_soft, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_pred = deepsad_soft.astype(float) + autonn_soft.astype(float) + tabnet_soft.astype(float) > 1.5\n",
    "soft_disp = ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), soft_pred, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test.to_numpy(), soft_pred))\n",
    "print(precision_score(y_test.to_numpy(), soft_pred))\n",
    "print(recall_score(y_test.to_numpy(), soft_pred))\n",
    "print(f1_score(y_test.to_numpy(), soft_pred))\n",
    "print(geometric_mean_score(y_test.to_numpy(), soft_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(y_true, y_pred, target_tpr):\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "    index = np.argmin(np.abs(tpr - target_tpr))\n",
    "    return threshold[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_threshold_09990 = get_threshold(y_test.to_numpy(), deepsad_soft, 0.9990)\n",
    "deepsad_threshold_09950 = get_threshold(y_test.to_numpy(), deepsad_soft, 0.9950)\n",
    "deepsad_threshold_09900 = get_threshold(y_test.to_numpy(), deepsad_soft, 0.9900)\n",
    "deepsad_threshold_09800 = get_threshold(y_test.to_numpy(), deepsad_soft, 0.9800)\n",
    "deepsad_threshold_09700 = get_threshold(y_test.to_numpy(), deepsad_soft, 0.9700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autonn_threshold_09990 = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, 0.9990)\n",
    "autonn_threshold_09950 = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, 0.9950)\n",
    "autonn_threshold_09900 = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, 0.9900)\n",
    "autonn_threshold_09800 = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, 0.9800)\n",
    "autonn_threshold_09700 = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, 0.9700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_threshold_09990 = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, 0.9990)\n",
    "tabnet_threshold_09950 = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, 0.9950)\n",
    "tabnet_threshold_09900 = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, 0.9900)\n",
    "tabnet_threshold_09800 = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, 0.9800)\n",
    "tabnet_threshold_09700 = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, 0.9700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(y_true, y_pred, threshold):\n",
    "    matrix = confusion_matrix(y_true, y_pred > threshold)\n",
    "    return matrix[1][1] / (matrix[0][1] + matrix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09900).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09900).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09900).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09990).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09990).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09990).astype(int)\n",
    "or_pred_09990 = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred_09990, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'}, values_format = '.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09950).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09950).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09950).astype(int)\n",
    "or_pred_09950 = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred_09950, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'}, values_format = '.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09900).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09900).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09900).astype(int)\n",
    "or_pred_09900 = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred_09900, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'}, values_format = '.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09800).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09800).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09800).astype(int)\n",
    "or_pred_09800 = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred_09800, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'}, values_format = '.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_hard = (deepsad_soft > deepsad_threshold_09700).astype(int)\n",
    "autonn_hard = (autonn_soft > autonn_threshold_09700).astype(int)\n",
    "tabnet_hard = (tabnet_soft > tabnet_threshold_09700).astype(int)\n",
    "or_pred_09700 = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test.to_numpy(), or_pred_09700, normalize = 'true', cmap = plt.cm.Blues, text_kw = {'fontsize': 'x-large'}, values_format = '.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsad_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.999, 0.90, 100)\n",
    "deepsad_ratio = []\n",
    "autonn_ratio = []\n",
    "tabnet_ratio = []\n",
    "majority_ratio = []\n",
    "or_ratio = []\n",
    "soft_ratio = []\n",
    "\n",
    "for threshold in tqdm(x):\n",
    "    deepsad_threshold = get_threshold(y_test.to_numpy(), deepsad_soft, threshold)\n",
    "    autonn_threshold = get_threshold(an_df['Predicted Label'].to_numpy(), autonn_soft, threshold)\n",
    "    tabnet_threshold = get_threshold(tabnet_model.y_test.to_numpy(), tabnet_soft, threshold)\n",
    "\n",
    "    deepsad_hard = (deepsad_soft > deepsad_threshold).astype(int)\n",
    "    autonn_hard = (autonn_soft > autonn_threshold).astype(int)\n",
    "    tabnet_hard = (tabnet_soft > tabnet_threshold).astype(int)\n",
    "\n",
    "    majority_pred = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) > 1.5).astype(int)\n",
    "    or_pred = (np.stack([deepsad_hard, autonn_hard, tabnet_hard]).sum(axis = 0) != 0).astype(int)\n",
    "    soft_pred = (np.stack([deepsad_soft, autonn_soft, tabnet_soft]).sum(axis = 0) > deepsad_threshold + autonn_threshold + tabnet_threshold).astype(int)\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), deepsad_hard)\n",
    "    deepsad_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), autonn_hard)\n",
    "    autonn_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), tabnet_hard)\n",
    "    tabnet_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), majority_pred)\n",
    "    majority_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), or_pred)\n",
    "    or_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))\n",
    "\n",
    "    matrix = confusion_matrix(y_test.to_numpy(), soft_pred)\n",
    "    soft_ratio.append(matrix[0][1] / (matrix[0][0] + matrix[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.linspace(0.999, 0.90, 100), deepsad_ratio, label = 'DeepSAD')\n",
    "# plt.plot(np.linspace(0.999, 0.90, 100), autonn_ratio, label = 'Autoencoder + MLP')\n",
    "# plt.plot(np.linspace(0.999, 0.90, 100), tabnet_ratio, label = 'TabNet')\n",
    "plt.plot(np.linspace(0.999, 0.90, 100), majority_ratio, label = 'Majority Vote')\n",
    "plt.plot(np.linspace(0.999, 0.90, 100), or_ratio, label = 'OR Vote')\n",
    "plt.plot(np.linspace(0.999, 0.90, 100), soft_ratio, label = 'Soft Vote')\n",
    "\n",
    "plt.xlabel('TPR')\n",
    "plt.ylabel('FPR')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_ratio = soft_ratio\n",
    "danger_ratio = [x - y for x, y in zip(majority_ratio, soft_ratio)]\n",
    "caution_ratio = [x - y for x, y in zip(or_ratio, majority_ratio)]\n",
    "normal_ratio = [1 - x for x in or_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = [n * 1 + c * 3 + d * 5 + p * 10 for n, c, d, p in zip(normal_ratio, caution_ratio, danger_ratio, prohibit_ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0.999, 0.90, 100), elapsed_time, label = 'elapsed time (s)')\n",
    "\n",
    "plt.xlabel('TPR')\n",
    "plt.ylabel('expected elapsed time (s)')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.linspace(0.999, 0.90, 100) == 0.9990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_ratio[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongjae_rba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd79beb0aae4abe819c785a6067139c3e0331b942f5d097b7bed8a75a3313abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
