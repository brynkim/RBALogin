{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/anaconda3/envs/dongjae_rba/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from deepod.models.tabular import DevNet, PReNet, DeepSAD, FeaWAD, RoSAS\n",
    "from deepod.metrics import tabular_metrics\n",
    "# from autoencodernn import *\n",
    "# from tapnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, Trials, tpe, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./checkpoint/train_df.csv', index_col = 0)\n",
    "valid_df = pd.read_csv('./checkpoint/valid_df.csv', index_col = 0)\n",
    "test_df = pd.read_csv('./checkpoint/test_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./checkpoint/x_train.csv')\n",
    "y_train = pd.read_csv('./checkpoint/y_train.csv')\n",
    "\n",
    "X_valid = pd.read_csv('./checkpoint/x_valid.csv')\n",
    "y_valid = pd.read_csv('./checkpoint/y_valid.csv')\n",
    "\n",
    "X_test = pd.read_csv('./checkpoint/x_test.csv')\n",
    "y_test = pd.read_csv('./checkpoint/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_preprocessing(df1, df2, df3):\n",
    "    df1['type'] = 'train'\n",
    "    df2['type'] = 'valid'\n",
    "    df3['type'] = 'test'\n",
    "\n",
    "    df = pd.concat([df1, df2, df3]).reset_index(drop = True)\n",
    "\n",
    "    country_onehot = pd.get_dummies(df['country']).astype(int)\n",
    "    risk_grades = df[['region_risk_grade', 'city_risk_grade', 'name_risk_grade']]\n",
    "    browser_onehot = pd.get_dummies(df['browser_name']).astype(int)\n",
    "    os_onehot = pd.get_dummies(df['os_name']).astype(int)\n",
    "    legacys = df[['browser_is_legacy', 'os_is_legacy']]\n",
    "    device_types = pd.get_dummies(df['device_type']).astype(int)\n",
    "    rtts = df['rtt']\n",
    "    type = df['type']\n",
    "    label = df['label']\n",
    "    df = pd.concat([country_onehot, risk_grades, browser_onehot, os_onehot, legacys, device_types, rtts, type, label], axis = 1)\n",
    "\n",
    "    df1 = df[df['type'] == 'train'].drop('type', axis = 1)\n",
    "    df2 = df[df['type'] == 'valid'].drop('type', axis = 1)\n",
    "    df3 = df[df['type'] == 'test'].drop('type', axis = 1)\n",
    "\n",
    "    return df1, df2, df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detection Model\n",
      "start - 2023-12-11 17:29:43.038737\n",
      "Start Training...\n",
      "ensemble size: 1\n",
      "training data counter: Counter({0: 971745, -1: 94036})\n",
      "MLPnet(\n",
      "  (network): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (linear): Linear(in_features=220, out_features=100, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (linear): Linear(in_features=100, out_features=50, bias=False)\n",
      "      (act_layer): ReLU()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (linear): Linear(in_features=50, out_features=128, bias=False)\n",
      "      (act_layer): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch  1, training loss: 34.687329, time: 95.7s\n",
      "epoch 10, training loss: 1.323776, time: 87.8s\n",
      "epoch 20, training loss: 0.993548, time: 87.7s\n",
      "epoch 30, training loss: 0.952602, time: 78.4s\n",
      "epoch 40, training loss: 0.844039, time: 78.4s\n",
      "epoch 50, training loss: 0.795631, time: 79.1s\n",
      "epoch 60, training loss: 0.732082, time: 77.2s\n",
      "epoch 70, training loss: 0.791136, time: 78.4s\n",
      "epoch 80, training loss: 0.979130, time: 78.9s\n",
      "epoch 90, training loss: 0.697807, time: 78.4s\n",
      "epoch100, training loss: 0.780566, time: 78.2s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 16653/16653 [00:24<00:00, 678.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 16653/16653 [00:24<00:00, 683.44it/s]\n",
      "testing: 100%|██████████| 2379/2379 [00:03<00:00, 723.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with <deepod.models.tabular.dsad.DeepSAD object at 0x7fb09596d2e0>\n",
      "Train - AUC: 0.7752313003374378, AP: 0.18231019854375657, F1: 0.31301570028171\n",
      "Valid - AUC: 0.7748725965818417, AP: 0.18207407279873802, F1: 0.3126856693918637\n",
      "end - 2023-12-11 19:46:30.562138 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Anomaly Detection\n",
    "print('Anomaly Detection Model')\n",
    "ad_model_names = ['DevNet', 'PReNet', 'DeepSAD', 'FeaWAD', 'RoSAS']\n",
    "ad_models = [\n",
    "    # DevNet(),           # 86.5s\n",
    "    # PReNet(),           # Too long. (2.4 hours)\n",
    "    DeepSAD(),          # 75.4s\n",
    "    # FeaWAD(epochs = 10000, lr = 0.01),           # Very fast but poor.\n",
    "    # RoSAS(),            # Too long.\n",
    "]\n",
    "\n",
    "train_df_ad, valid_df_ad, test_df_ad = anomaly_preprocessing(train_df, valid_df, test_df)\n",
    "\n",
    "X_train_ad = train_df_ad.drop(['label'], axis = 1)\n",
    "y_train_ad = train_df_ad['label']\n",
    "\n",
    "X_valid_ad = valid_df_ad.drop(['label'], axis = 1)\n",
    "y_valid_ad = valid_df_ad['label']\n",
    "\n",
    "X_test_ad = test_df_ad.drop(['label'], axis = 1)\n",
    "y_test_ad = test_df_ad['label']\n",
    "\n",
    "for model_name, model in zip(ad_model_names, ad_models):\n",
    "    print('start -', datetime.now())\n",
    "    \n",
    "    model.fit(X_train_ad.to_numpy(), y_train_ad.to_numpy())\n",
    "    print('Train Finish')\n",
    "    pred_train = (model.decision_function(X_train_ad.to_numpy()) > 0.5).astype(int)\n",
    "    auc_train, ap_train, f1_train = tabular_metrics(y_train_ad, pred_train)\n",
    "    \n",
    "    pred_valid = (model.decision_function(X_valid_ad.to_numpy()) > 0.5).astype(int)\n",
    "    auc_valid, ap_valid, f1_valid = tabular_metrics(y_valid_ad, pred_valid)\n",
    "    \n",
    "    print(f'Trained with {model}')\n",
    "    print(f'Train - AUC: {auc_train}, AP: {ap_train}, F1: {f1_train}')\n",
    "    print(f'Valid - AUC: {auc_valid}, AP: {ap_valid}, F1: {f1_valid}')\n",
    "\n",
    "    models.append(model)\n",
    "    print('end -', datetime.now(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open('./checkpoint/deepsad2.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPEROPT TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'epochs': hp.quniform('epochs', 10, 200, 10),\n",
    "    'batch_size': hp.quniform('batch_size', 16, 128, 16),\n",
    "    'lr': hp.uniform('lr', 1e-7, 1e-1),\n",
    "    'rep_dim': hp.quniform('rep_dim', 64, 256, 16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    model = DeepSAD(epochs = int(space['epochs']), batch_size = int(space['batch_size']), lr = float(space['lr']), rep_dim = int(space['rep_dim']), verbose = 0)\n",
    "\n",
    "    model.fit(X_train_ad.to_numpy(), y_train_ad.to_numpy())\n",
    "    \n",
    "    pred_valid = (model.decision_function(X_valid_ad.to_numpy()) > 0.5).astype(int)\n",
    "    auc_valid, ap_valid, f1_valid = tabular_metrics(y_valid_ad, pred_valid)\n",
    "    \n",
    "    return (1 - auc_valid) ** 2 + (1 - ap_valid) ** 2 + (1 - f1_valid) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(fn = objective, space = search_space, algo = tpe.suggest, max_evals = 20, trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSAD(epochs = int(best['epochs']), batch_size = int(best['batch_size']), lr = float(best['lr']), rep_dim = int(best['rep_dim']), verbose = 2)\n",
    "\n",
    "model.fit(X_train_ad.to_numpy(), y_train_ad.to_numpy())\n",
    "\n",
    "pred_train = (model.decision_function(X_train_ad.to_numpy()) > 0.5).astype(int)\n",
    "auc_train, ap_train, f1_train = tabular_metrics(y_train_ad, pred_train)\n",
    "\n",
    "pred_valid = (model.decision_function(X_valid_ad.to_numpy()) > 0.5).astype(int)\n",
    "auc_valid, ap_valid, f1_valid = tabular_metrics(y_valid_ad, pred_valid)\n",
    "\n",
    "pred_test = (model.decision_function(X_test_ad.to_numpy()) > 0.5).astype(int)\n",
    "auc_test, ap_test, f1_test = tabular_metrics(y_test_ad, pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongjae_rba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd79beb0aae4abe819c785a6067139c3e0331b942f5d097b7bed8a75a3313abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
